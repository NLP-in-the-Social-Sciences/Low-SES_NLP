{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements \n",
    "# i suggest to use a virtual environment when installing these packages \n",
    "!pip install -U pandas\n",
    "!pip install -U scikit-learn\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#keyphrases.csv in shared drive (not public data)\n",
    "df = pd.read_csv('keyphrases.csv') # file containing keyphrases from out old narratives\n",
    "keyphrases = df['ngram_range_keyphrases'].to_numpy()\n",
    "\n",
    "#embed keyphrases\n",
    "corpus_embeddings = embedding_model.encode(sentences=keyphrases, \n",
    "                                           convert_to_numpy=True,\n",
    "                                           show_progress_bar=True)\n",
    "\n",
    "#normalization (optional)\n",
    "corpus_embeddings = corpus_embeddings / np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_arr  = []\n",
    "\n",
    "# compute kmeans for k = 5 to k = 15\n",
    "for n_clusters in range(5, 16): \n",
    "    clustering_model = KMeans(n_clusters=n_clusters)\n",
    "    clustering_model.fit(corpus_embeddings)\n",
    "    cluster_assignment = clustering_model.labels_\n",
    "    kmeans_arr.append(np.array(cluster_assignment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_sentences = [[[] for _ in range(n_clusters)] for n_clusters in range(5, 16)]\n",
    "\n",
    "for n_clusters, arr in enumerate(kmeans_arr):\n",
    "    for phrase_id, cluster_id in enumerate(arr):\n",
    "        clustered_sentences[n_clusters][cluster_id].append(keyphrases[phrase_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "index = 10 # 10 clusters seemed to be the best\n",
    "with open(f'clustered_sentences_{index}.json', 'w') as f:\n",
    "\n",
    "    json.dump(clustered_sentences[index], f, indent=4, sort_keys=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpR_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
